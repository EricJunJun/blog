# 复制与故障转移
> Redis集群中的节点分为主节点(master)和从节点(slave),其中主节点用于处理槽,而从节点则用于复制某个主节点,并在被复制的主节点下线时,代替下线主节点继续处理命令请求.

例子:

正常:

![例子](https://github.com/gdufeZLYL/blog/blob/master/images/20180518084515.png)

![图17-32 设置节点7004和几点7005成为节点7000的从节点](https://github.com/gdufeZLYL/blog/blob/master/images/20180518084546.png)

![表17-1 集群各个节点的当前状态](https://github.com/gdufeZLYL/blog/blob/master/images/20180518084659.png)

节点7000下线,节点7004成为新的主节点:

![节点7004成为新的主节点](https://github.com/gdufeZLYL/blog/blob/master/images/20180518084828.png)

![表17-2 集群各个节点的当前状态](https://github.com/gdufeZLYL/blog/blob/master/images/20180518084916.png)

节点7000上线,成为节点7004的从节点:

![图17-34 重新上线的节点7000成为节点7004的从节点](https://github.com/gdufeZLYL/blog/blob/master/images/20180518085040.png)

![表17-3 集群各个节点的当前状态](https://github.com/gdufeZLYL/blog/blob/master/images/20180518085201.png)

# 设置从节点
向一个节点发送命令:
```
CLUSTER REPLICATE <node_id>
```
可以让接收命令的节点成为node_id所指定节点的从节点,并开始对主节点进行复制:

![步骤](https://github.com/gdufeZLYL/blog/blob/master/images/20180518085721.png)

![步骤](https://github.com/gdufeZLYL/blog/blob/master/images/20180518085811.png)

图17-35展示了节点7004在复制节点7000时的clusterState结构:

![图17-35 节点7004的clusterState结构](https://github.com/gdufeZLYL/blog/blob/master/images/20180518091358.png)

![说明](https://github.com/gdufeZLYL/blog/blob/master/images/20180518091309.png)

一个节点成为从节点,并开始复制某个主节点这一信息会通过消息发送给集群中的其他节点,最终集群中的所有节点都会知道某个从节点正在复制某个主节点.

集群中的所有节点都会在代表主节点的clusterNode结构的slaves属性和numslaves属性中记录正在复制这个主节点的从节点名单:
```c++
struct clusterNode {
    // ...

    // 正在复制这个主节点的从节点数量
    int numslaves;

    // 一个数组
    // 每个数组项指向一个正在复制这个主节点的从节点的clusterNode结构
    struct clusterNode **slaves;

    // ...
};
```
例子:

![例子](https://github.com/gdufeZLYL/blog/blob/master/images/20180518092303.png)

![图17-36 集群中的各个节点为节点7000创建的clusterNode结构](https://github.com/gdufeZLYL/blog/blob/master/images/20180518092535.png)

# 故障检测
集群中的每个节点都会定期地向集群中的其他节点发送PING消息,以此来检测对方是否在线,如果接收PING消息的节点没有在规定的时间内,向发送PING消息的节点返回PONG消息,那么发送PING消息的节点就会将接收PING消息的节点标记为疑似下线(probable fail PFAIL)

例子:

![例子](https://github.com/gdufeZLYL/blog/blob/master/images/20180518094226.png)

集群中的各个节点会通过互相发送消息的方式来交换集群中各个节点的状态信息,例如某个节点是处于在线状态、疑似下线状态(PFAIL),还是已下线状态(FAIL).

当一个主节点A通过消息得知主节点B认为主节点C进入了疑似下线状态时,主节点A会在自己的clusterState.nodes字典中找到主节点C对应的clusterNode结构,并将主节点B的下线报告(failure report)添加到clusterNode结构的fail_reports链表里面:
```c++
struct clusterNode {
    // ...

    // 一个链表,记录了所有其他节点对该节点的下线报告
    list *fail_reports;

    // ...
};
```
每个下线报告由一个clusterNodeFailReport结构表示:
```c++
struct clusterNodeFailReport {
    // 报告目标节点已经下线的节点
    struct clusterNode *node;

    // 最后一次从node节点收到下线报告的时间
    // 程序使用这个时间戳来检查下线报告是否过期
    // (与当前时间相差太久的下线报告会被删除)
    mstime_t time;
} typedef clusterNodeFailReport;
```
例子:

![例子](https://github.com/gdufeZLYL/blog/blob/master/images/20180518095824.png)

![图17-38 节点7000的下线报告](https://github.com/gdufeZLYL/blog/blob/master/images/20180518095852.png)

如果在一个集群里面,半数以上负责处理槽的主节点都将某个主节点x报告为疑似下线,那么这个主节点x将被标记为已下线(FAIL),将主节点x标记为已下线的节点会向集群广播一条关于主节点x的FAIL消息,所有收到这条FAIL消息的节点都会立即将主节点x标记为已下线.

例子:

![例子](https://github.com/gdufeZLYL/blog/blob/master/images/20180518100939.png)

![图17-39 节点7001向集群广播FAIL消息](https://github.com/gdufeZLYL/blog/blob/master/images/20180518101003.png)

# 故障转移

![故障转移](https://github.com/gdufeZLYL/blog/blob/master/images/20180518101056.png)

# 选举新的主节点
新的主节点是通过选举产生的,以下是集群选举新的主节点发方法(基于Raft算法的领头选举方法):
1. 集群的配置纪元是一个自增计数器,它的初始值为0.
2. 当集群里的某个节点开始一次故障转移操作时,集群配置纪元的值会被增一.
3. 对于每个配置纪元,集群里每个负责处理槽的主节点都有一次投票的机会,而第一个向主节点要求投票的从节点将获得主节点的投票.
4. 当从节点发现自己正在复制的主节点进入已下线状态时,从节点会向集群广播一条CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST消息,要求所有收到这条消息、并且具有投票权的主节点向这个从节点投票.
5. 如果一个主节点具有投票权(它正在负责处理槽),并且这个主节点尚未投票给其他从节点,那么主节点将向要求投票的从节点返回一条CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK消息,表示这个主节点支持从节点成为新的主节点.
6. 每个参与选举的从节点都会接收CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK消息,并根据自己收到了多少条这种消息来统计自己活得了多少主节点的支持.
7. 如果集群里有N个具有投票权的主节点,那么当一个从节点收集到大于等于N/2+1张支持票时,这个从节点就会当选为新的主节点.
8. 因为在每一个配置纪元里面,每个具有投票权的主节点只能投一次票,所以如果有N个主节点进行投票,那么具有大于等于N/2+1张支持票的从节点只会有一个,这确保了新的主节点只会有一个.
9. 如果在一个配置纪元里面没有从节点能收集到足够多的支持票,那么集群进入一个新的配置纪元,并再次进行选举,直到选出新的主节点为止.

